<!DOCTYPE HTML>
<html>
	<head>
		<title>Kenneth Wilber • Programming Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body>
		<div id="wrapper">
			<header id="header" style="padding-top: 60px; text-align:center;">
				<div class="inner">
					<a href="index.html"> <h3 style="color: white; font-size: larger;">Kenneth Wilber • Programming Portfolio</h3></a>
				</div>
			</header>
			<div id="main">
				<div class="inner">
					<h1 style="text-align: center;">Text Generator</h1>							  
					<span class="image main">
						<video width="480" height="480" autoplay muted loop style="margin: auto; display: block;">
							<source src="videos/text_generation.mp4" type="video/mp4"/>
						</video>
						<p style="text-align: center;">The above video shows my project <br> generating text given the prompt <br> "I believe the meaning of life is." </p>
					</span>
					<div style="background-color: black; margin-left: 20%; margin-right: 20%;">
						<p style="margin-left: 5px; margin-right:5px;">I developed a PyTorch model to generate text trained on a dataset of Shakespeare plays using a small-scale version of the very same “self-attention” technique used by popular tools like ChatGPT and Bard.</p>
						<p style="margin-left: 5px; margin-right:5px;">The tool generates text by predicting the next token (word or character) in a sequence of tokens. For each token in the input, three vectors of equal length are generated, respectively called the token's key, and query, and output vectors.  In essence, the query represents what a given token is interested in, the key what information that token has to offer. For any given pair of tokens, the amount of “interest” one token has with another is the dot product of one's query vector with the other's key vector.</p>
						<p style="margin-left: 5px; margin-right:5px;">Once an interest level between every pair of tokens is calculated, the tokens “speak” to each other. Each token creates a new vector which is the sum of each of the other tokens' output vectors weighted by the “interest” between the pair.</p>
						<p style="margin-left: 5px; margin-right:5px;">This is the essence of the unique technique that allows large language models to intake an arbitrarily sized sequence of tokens and process those tokens into features useful for predicting the next token in the input sequence.</p>
						<p style="margin-left: 5px; margin-right:5px;"></p>
					</div>
				</div>
			</div>
		</div>

		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

	</body>
</html>