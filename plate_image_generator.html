<!DOCTYPE HTML>
<html>
	<head>
		<title>Kenneth Wilber • Programming Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body>
		<div id="wrapper">
			<header id="header" style="padding-top: 60px; text-align:center;">
				<div class="inner">
					<a href="index.html"> <h3 style="color: white; font-size: larger;">Kenneth Wilber • Programming Portfolio</h3></a>
				</div>
			</header>
			<div id="main">
				<div class="inner">
					<h1 style="text-align: center;">Image Generator</h1>							  
					<span class="image main">
						<video width="480" height="480" autoplay muted loop style="margin: auto; display: block;">
							<source src="videos/image_generation.mp4" type="video/mp4"/>
						</video>
						<p style="text-align: center;">The above video shows my project <br> generating images given a prompt. </p>
					</span>
					<div style="background-color: black; margin-left: 20%; margin-right: 20%;">
						<p style="margin-left: 5px; margin-right:5px; ">I created and trained a PyTorch model that uses a technique called “latent diffusion” to generate images. First, I created a dataset of noisy images by adding random values to the pixels of images from the MNIST fashion dataset. Then, I trained a convolutional neural network to predict the noise in a given image. Finally, I was able to generate new images not contained in the original dataset by starting with an image of completely random noise, then repeatedly subtracting the a small amount of the predicted noise from the image until it eventually resembles a clothing item.</p>
						<p style="margin-left: 5px; margin-right:5px; ">There is one more complication however: the “latent” part of “latent diffusion.” As you increase the size and variety of images in the dataset, it quickly becomes computationally impractical to train networks of the necessary size.  Modern image generators get around this is issue by training models and generating images within something called the “latent space” - a fancy term for what’s essentially a compressed representation of the image. To compress images, you add two new convolutional neural networks to the process: an encoder and a decoder. These networks are trained together to respectively compress and decompress images in the dataset. After compressing images during training and during the generation process, one can simply use the decoder to decompress the images back into their original formats.</p>
					</div>
				</div>
			</div>
		</div>

		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

	</body>
</html>